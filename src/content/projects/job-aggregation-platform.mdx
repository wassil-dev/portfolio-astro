---
title: "Job Aggregation Data Platform"
description: "Production-grade data engineering platform with web scraping pipelines, ETL workflows, and intelligent job matching system."
tags: ["Apache Airflow", "Web Scraping", "ETL", "PostgreSQL", "FastAPI", "Docker"]
cover: "/images/job-platform-cover.png"
date: "2025-01-06"
github: "https://github.com/wassil-dev/job-aggregation-platform"
---

## Overview

A production-ready data engineering platform that scrapes, processes, and delivers personalized job notifications. Built with Apache Airflow for orchestration, the system automates the entire pipeline from data collection to intelligent matching.

**Impact:** 90% reduction in job discovery time through automated aggregation and personalized notifications.

## Architecture

**Orchestration:** Apache Airflow 3.1.0 with separated DAG Processor for optimal performance

**Storage:**
- Data Lake: MinIO (S3-compatible) with date-partitioned storage
- Data Warehouse: PostgreSQL 16 with full-text search indexes

**Application:** FastAPI backend with intelligent matching engine and multi-language support

**Infrastructure:** Docker Compose with resource limits, health checks, and automatic recovery

## Key Features

### Automated Data Pipeline
- Web scraping from multiple job boards with rate limiting
- Hourly synchronization with incremental updates
- ETL workflows with staging and production layers
- Hash-based deduplication across sources

### Intelligent Matching System
- Full-text search with PostgreSQL GIN indexes
- User preference matching (keywords, locations, work modes)
- Zero-duplicate notification tracking
- Real-time delivery via messaging API

### Production Engineering
- 99.5% uptime with health monitoring
- Safe restart scripts preventing missed DAG runs
- Automated database cleanup with retention policies
- Resource-limited services (CPU/memory quotas)
- Comprehensive logging with rotation

## Performance Optimizations

- **99.8% reduction** in Airflow metadata size through XCom optimization
- **70% storage savings** with Parquet compression
- **10-100x faster queries** using full-text search indexes
- Processes thousands of jobs in under 5 minutes

## Technical Challenges Solved

**Preventing Redundant Runs**
- Problem: Airflow queues all missed schedules during downtime
- Solution: Safe shutdown scripts that pause DAGs before restart

**Cross-Platform Deduplication**
- Problem: Same job appears on multiple sources
- Solution: Hash-based deduplication using normalized descriptions

**Memory Management**
- Problem: DAG parsing consumed excessive memory
- Solution: Resource limits and DAG serialization

## Tech Stack

**Orchestration:** Apache Airflow 3.1.0
**Languages:** Python 3.12, SQL
**Storage:** PostgreSQL 16, MinIO
**Web Scraping:** Requests, BeautifulSoup
**API:** FastAPI
**Infrastructure:** Docker Compose
**Libraries:** Pandas, SQLAlchemy, Boto3

## Results

- Thousands of jobs aggregated hourly from multiple sources
- Multi-language support (French, English, Arabic)
- Zero duplicate notifications through intelligent tracking
- Production-stable with 99.5% uptime
- Scalable to 50-100 concurrent workflows
